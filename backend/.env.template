######################################################
#    Template Env File to help create env file       #
#        for production and dev deployments.         #
######################################################

# 'EVAL' for running evaluation and 'PROD' for production build.
# ENVIRONMENT="PROD"

#####################################################
#           LLM Model Serving API Config            #
#####################################################

# SERVICE="OLLAMA"
# ROLE_USER="user"
# ROLE_MODEL="assistant"

# For prod
# OLLAMA_URL="http://fairway_ollama:11434"

# For dev
# OLLAMA_URL="http://host.docker.internal:11434"

############# DEFINE LLM MODEL IN USE ##############
# For DEV
# LLM_MODEL="qwen2.5-coder:14b-instruct-q6_K"
# LLM_MODEL="qwen-2.5-coder-32b"
# LLM_MODEL="gpt-4o-2024-08-06"

# For Prod
# LLM_MODEL="llama3.1:8b-instruct-q8_0"
# LLM_MODEL="phi4:14b-q8_0"
# LLM_MODEL="mistral-small:24b-instruct-2501-q8_0"

###################### LLM PARAMETERS ######################
# TEMPERATURE=0.3
# NUM_CTX=8192
# TOP_P=0.9
# KEEP_ALIVE=30m  # For ollama model eviction
# KEEP_ALIVE=5m   # For evaluation phase
####################################################

#####################################################
#         Celery Task Queue Configuration           #
#####################################################
# BROKER_URL="redis://redis:6379/0"
# RESULT_BACKEND="redis://redis:6379/0"
# WORKER_CONCURRENCY=5
# WORKER_PREFETCH_MULTIPLIER=3
# TIMEZONE='UTC'
# ENABLE_UTC=True
# TASK_TRACK_STARTED=True
# TASK_RATE_LIMIT_ADD='3/s'
# BROKER_CONNECTION_RETRY_ON_STARTUP=True
# RESULT_EXPIRES=57600
# TASK_ACKS_LATE=True
# TASK_REJECT_ON_WORKER_LOST=True
# TASK_TIME_LIMIT=7200
# WORKER_MAX_MEMORY_PER_CHILD=250000

#####################################################
#               Other Configurations                #
#####################################################

# FEEDBACK_DB_PATH="/app/data/feedback.db"

# Access Endpoints
BASE_DOI_RESOLVER = "https://doi.org/api/handles/"
BASE_ZENODO_RESOLVER = "https://zenodo.org/api/records/"
BASE_DRYAD_RESOLVER = "https://datadryad.org/api/v2/datasets/"
BASE_HUGGING_FACE_RESOLVER = "https://huggingface.co/api/datasets/"

# Access TOKENs
# zenodo_access_token=""
# openai_key=""